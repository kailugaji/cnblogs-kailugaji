<h1 style="text-align: center;"><span style="font-family: 'comic sans ms', sans-serif;">深度多视图子空间聚类</span></h1>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">作者：凯鲁嘎吉 - 博客园&nbsp;<a href="http://www.cnblogs.com/kailugaji/" target="_blank">http://www.cnblogs.com/kailugaji/</a></span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">1.&nbsp;Deep Multi-view Subspace Clustering with Unified and Discriminative Learning</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 这部分是对Deep Multi-view Subspace Clustering with Unified and Discriminative Learning这篇文章的展开与叙述。与其他多视图聚类方法相比，深度多视图子空间聚类取得了良好的性能。然而，现有的深度多视图子空间聚类只考虑所有视图的全局结构，忽略了每个视图之间的局部几何结构。此外，他们不能学习不同视图的不同簇的判别特征，即簇间差异。为了解决这些问题，本文提出了一种基于统一判别学习的深度多视图子空间聚类算法(DMSC-UDL)。DMSCUDL将全局结构和局部结构与自表示层相结合。全局结构和局部结构相互促进，使同一类样本之间的距离变小。为了在不同视图的不同簇中进一步生成样本，DMSC-UDL在不同视图之间使用了判别约束。这样，DMSC-UDL使得同一簇的样本具有较大的权值，而不同簇的样本具有较小的权值。因此，它可以学习一个更好的多视图聚类共享连接矩阵。大量的实验结果表明，本文提出的多视图聚类方法在性能上优于现有的几种多视图聚类方法。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202103/1027447-20210326153110745-475200844.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202103/1027447-20210326153117838-1694920780.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202103/1027447-20210326153124391-1778354787.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202103/1027447-20210326153130747-357131365.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">2.&nbsp;Multi-view Subspace Clustering Networks with Local and Global Graph Information</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 这部分是对Multi-view Subspace Clustering Networks with Local and Global Graph Information这篇文章的展开与叙述。</span><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">这项研究调查了多视图子空间聚类的问题，其目的是探索从不同领域或测量收集的数据的底层分组结构。由于数据在许多实际应用中并不总是符合线性子空间模型，因此大多数现有的基于浅层线性子空间模型的多视图子空间聚类方法在实践中可能会失败。此外，在大多数多视图子空间聚类方法中，通常会忽略多视图数据的底层图信息。针对上述局限性，本文提出了一种新颖的具有局部和全局图信息的多视图子空间聚类网络，称为MSCNLG。具体而言，在多个视图上使用自编码器网络以实现适合于线性假设的潜在平滑表示。同时，通过将融合的多视图图信息集成到自表示层中，提出的MSCNLG获得了共享的多视图子空间共享表示，可通过采用标准的谱聚类算法获得聚类结果。作为一种端到端的可训练框架，该方法充分研究了多视图的有价值信息。在六个基准数据集上进行的全面实验验证了所提出的MSCNLG的有效性和优越性。</span></p>
<p><img src="https://img2020.cnblogs.com/blog/1027447/202103/1027447-20210326204529921-1735924187.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></p>
<p><img src="https://img2020.cnblogs.com/blog/1027447/202103/1027447-20210326204536371-191313656.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></p>
<p><img src="https://img2020.cnblogs.com/blog/1027447/202103/1027447-20210326204542735-854305672.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">3. 参考文献</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[1]&nbsp;Q. Wang, J. Cheng, Q. Gao, G. Zhao and L. Jiao, "<a href="https://ieeexplore.ieee.org/document/9204408" target="_blank">Deep Multi-view Subspace Clustering with Unified and Discriminative Learning</a>," IEEE Transactions on Multimedia, doi: 10.1109/TMM.2020.3025666.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[2]&nbsp;Zhenga Q,&nbsp; J&nbsp; Zhua,&nbsp; Ma Y, et al, "<a href="https://arxiv.org/pdf/2010.09323v3.pdf" target="_blank">Multi-view Subspace Clustering Networks with Local and Global Graph Information,"&nbsp;</a>2021, Neurocomputing.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">Code:&nbsp;<a href="https://github.com/ZQH92/MSCNLG" target="_blank">https://github.com/ZQH92/MSCNLG</a></span></p>
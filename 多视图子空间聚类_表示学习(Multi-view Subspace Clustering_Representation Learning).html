<h1 style="text-align: center;"><span style="font-family: 'comic sans ms', sans-serif;">多视图子空间聚类/表示学习(Multi-view Subspace Clustering/Representation Learning)</span></h1>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;">作者：凯鲁嘎吉 - 博客园&nbsp;<a href="http://www.cnblogs.com/kailugaji/" target="_blank">http://www.cnblogs.com/kailugaji/</a></span></p>
<ul>
<li><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&ldquo;横看成岭侧成峰，远近高低各不同。&rdquo;多视图聚类是最近一个较为热门的研究话题。这篇博文主要对<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/index.html" target="_blank">张长青</a>团队的五篇文章(1)"<a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Zhang_Low-Rank_Tensor_Constrained_ICCV_2015_paper.pdf" target="_blank">Low-Rank Tensor Constrained Multiview Subspace Clustering</a>"(2015 ICCV)，(2)"<a href="https://www.researchgate.net/profile/Huazhu-Fu/publication/339398157_Tensorized_Multi-view_Subspace_Representation_Learning/links/5f0efc95a6fdcc3ed7083bf0/Tensorized-Multi-view-Subspace-Representation-Learning.pdf" target="_blank">Tensorized Multi-view Subspace Representation Learning</a>"(2020 IJCV)，(3)"<a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Latent_Multi-View_Subspace_CVPR_2017_paper.pdf" target="_blank">Latent Multi-view Subspace Clustering</a>"(2017 CVPR)，(4)"<a href="https://www.researchgate.net/publication/328479701_Generalized_Latent_Multi-View_Subspace_Clustering" target="_blank">Generalized Latent Multi-View Subspace Clustering</a>"(2020 TPAMI)和(5)"<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16212/16594" target="_blank">Consistent and Specific Multi-View Subspace Clustering</a>"(2018 AAAI)的算法进行介绍。由于第三篇文章是第四篇文章中的一部分内容(线性部分)，因此第三篇文章直接参看"Generalized Latent Multi-View Subspace Clustering"中的前半部分内容即可。</span></li>
<li><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">第一篇文章主要是将低秩张量约束引入到了多视角子空间聚类，联合地学习各视角的子空间表达以同时挖掘视角内及视角间的高阶关联信息。</span></li>
<li><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">第二篇文章在第一篇文章的基础上，引入先验信息，可能是监督信息，来学习子空间表示，用于分类任务，如果先验信息没有的话，该方法就退化为第一篇文章的算法，用于无监督聚类任务。</span></li>
<li><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">而第三和第四篇文章主要是假设多个视图共享同一个公共子空间表示Z，而不是每个视图都有一个各自的子空间表示。第三篇是线性映射，第四篇新增了一个非线性映射，引入神经网络进行非线性映射，来学习公共的潜在表示H。</span></li>
<li><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">第五篇文章是在第一篇文章的基础上将每个视图的Z拆成两部分，一部分为视图共享的表示C，一部分为每个视图各自的差异性表示D。</span></li>
<li><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">多视图子空间聚类主要思想是通过某些算法得到子空间表示(可以是每个视图各自的，也可以是一个公共的)Z，然后构造相似度矩阵S，最后利用谱聚类算法来得到最终的聚类结果。</span></li>
</ul>
<h2><span style="font-family: 'comic sans ms', sans-serif;">1. 基础知识</span></h2>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121171636871-263585171.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121171651506-156362088.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121171701738-891725791.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">2.&nbsp;Low-Rank Tensor Constrained Multiview Subspace Clustering</span></h2>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121171734738-216615868.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121171744340-2140708655.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121171753919-250921173.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121171804996-1661910800.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;">&nbsp; &nbsp; <span style="color: #ff0000;">具体优化过程涉及到了矩阵的$L_{2,1}$范数与核范数的优化，E与G的优化详细见：</span></span><span style="font-family: 'comic sans ms', sans-serif; font-size: 18px;"><span style="color: #ff0000;"><span style="text-decoration: underline; color: #0000ff;"><span style="color: #0000ff; text-decoration: underline;"><a href="https://www.cnblogs.com/kailugaji/p/14613210.html" target="_blank">一类涉及矩阵范数的优化问题</a><a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/kailugaji/p/14613210.html"></a></span></span></span></span><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><span style="color: #ff0000;">。Z的优化中用到了置换/排列矩阵P的性质，置换矩阵是方阵，只取0和1两个值，且每行每列有且仅有一个1，置换矩阵也是正交矩阵，满足${P^T}P=P{P^T}=I$。</span><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121171814761-813028247.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 2015 ICCV论文代码可以在<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code.html" target="_blank">http://cic.tju.edu.cn/faculty/zhangchangqing/code.html</a>中找到，关于代码里的公式优化理解问题可以参看<a href="https://link.springer.com/article/10.1007/s11263-020-01307-0" target="_blank">2020 IJCV期刊文章</a>3.4 Optimization这部分，代码里置换矩阵P并未体现，z和g向量化也并未用到，而是使用reshape()进行重塑矩阵大小，因此可以将两篇文章的优化过程结合一起看。值得注意的是$G_m$因三个不同模态导致矩阵大小不同，用<a href="https://www.cnblogs.com/kailugaji/p/14613210.html#_lab2_0_4" target="_blank">奇异值阈值法</a>计算完之后矩阵的大小分别为N*(N*V), N*(N*V), (N*N)*V，之后再用reshape()将每个模态下的矩阵重塑为N*N*V，即$g_m$由此产生。$g_m$一变，$\alpha _m$也跟着变，每个模态下的$\alpha _m$大小也是N*N*V。</span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">3.&nbsp;Tensorized Multi-view Subspace Representation Learning</span></h2>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121171837740-863288257.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121171849946-915529228.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121171900351-204499844.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121171911065-1916095476.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">4.&nbsp;Generalized Latent Multi-View Subspace Clustering</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 这篇文章主要就是：X(数据，每个视图的)-&gt;H(潜在表示矩阵，公共的)-&gt;Z(系数矩阵，公共的)-&gt;W(构造相似度矩阵)-&gt;聚类。线性与非线性取决于X-&gt;H这里用的是线性映射，还是非线性映射(神经网络)。</span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121171951534-1547062661.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121172000648-2082240084.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121172010758-1719313399.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121172021429-1060471338.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121172033234-62270754.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;">在更新Z的过程中，用到了<a href="https://www.cnblogs.com/kailugaji/p/12676095.html" target="_blank">ADMM方法</a>，用辅助变量J代替原先核函数约束中的Z，原先是</span></p>
<p style="text-align: center;"><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;">$min \text{ } \frac{1}{2}\left \| H-HZ \right \|_{F}^{2}+\lambda \left \| Z \right \|_{*}$</span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;">现在增广拉格朗日函数为：</span></p>
<p style="text-align: center;"><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">$min \text{ } \frac{1}{2}\left \| H-HZ \right \|_{F}^{2}+\lambda \left \| J \right \|_{*}+\frac{\mu }{2}\left \| J-Z \right \|_{F}^{2}+Y(J-Z)$</span><br /><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">$Y=Y+\mu (J-Z)$</span></p>
<p style="text-align: left;"><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">在求解J时，本应该是$L=\lambda \left \| J \right \|_{*}+\frac{\mu }{2}\left \| J-Z \right \|_{F}^{2}+Y(J-Z)$，L对J求偏导，但是，现在在L的基础上多加了一项${(\frac{Y}{\mu } )}^{2}$，因为本身L是最小化的，加一项非负项不影响最小化这个目标，这样就能凑一个平方项，就可以用已有的<a href="https://www.cnblogs.com/kailugaji/p/14613210.html" target="_blank">奇异值阈值收缩公式</a>进行求解了。</span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202101/1027447-20210121172043804-2017502817.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">5.&nbsp;Consistent and Specific Multi-View Subspace Clustering</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202104/1027447-20210414103818427-2119827223.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><img src="https://img2020.cnblogs.com/blog/1027447/202104/1027447-20210414103824625-2132618781.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></p>
<p><img src="https://img2020.cnblogs.com/blog/1027447/202104/1027447-20210414103830896-864709624.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">6. 参考文献</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[1] C. Zhang et al., "<a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Zhang_Low-Rank_Tensor_Constrained_ICCV_2015_paper.pdf" target="_blank">Low-Rank Tensor Constrained Multiview Subspace Clustering</a>," 2015 IEEE International Conference on Computer Vision (ICCV), 2015.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">Code:&nbsp;<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code.html" target="_blank">http://cic.tju.edu.cn/faculty/zhangchangqing/code.html</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[2] 张长青. 基于自表达的多视角子空间聚类方法研究[D].天津大学,2016.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[3] C. Zhang et al., "<a href="https://www.researchgate.net/profile/Huazhu-Fu/publication/339398157_Tensorized_Multi-view_Subspace_Representation_Learning/links/5f0efc95a6fdcc3ed7083bf0/Tensorized-Multi-view-Subspace-Representation-Learning.pdf" target="_blank">Tensorized Multi-view Subspace Representation Learning</a>," International Journal of Computer Vision 9(2020).</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[4] C. Zhang et al., "<a href="https://www.researchgate.net/publication/328479701_Generalized_Latent_Multi-View_Subspace_Clustering" target="_blank">Generalized Latent Multi-View Subspace Clustering</a>," IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42, no. 1, pp. 86-99, 1 Jan. 2020.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[5] C. Zhang et al., "<a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Latent_Multi-View_Subspace_CVPR_2017_paper.pdf" target="_blank">Latent Multi-view Subspace Clustering</a>," 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[6] 张长青个人主页-天津大学智能与计算学部 <a href="http://cic.tju.edu.cn/faculty/zhangchangqing/research.html" target="_blank">http://cic.tju.edu.cn/faculty/zhangchangqing/research.html</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[7]&nbsp;<a id="cb_post_title_url" href="https://www.cnblogs.com/kailugaji/p/12676095.html">交替方向乘子法（Alternating Direction Method of Multipliers）</a>-凯鲁嘎吉 博客园</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[8]&nbsp;Shirui Luo, Changqing Zhang, Wei Zhang, Xiaochun Cao, "<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16212/16594" target="_blank">Consistent and Specific Multi-View Subspace Clustering</a>," AAAI. 2018.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">Code:&nbsp;<a href="https://github.com/XIAOCHUN-CAS/Consistent-and-Specific-Multi-View-Subspace-Clustering/" target="_blank">https://github.com/XIAOCHUN-CAS/Consistent-and-Specific-Multi-View-Subspace-Clustering/</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[9] 有关多视图的会议论文：<a href="https://github.com/lslrh/multi-view" target="_blank">https://github.com/lslrh/multi-view</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; &nbsp; 有关多视图论文的代码：<a href="https://github.com/liangnaiyao/multiview_learning" target="_blank">https://github.com/liangnaiyao/multiview_learning</a></span></p>
<h1 style="text-align: center;"><span style="font-family: 'comic sans ms', sans-serif;">COMPLETER: 基于对比预测的缺失视图聚类方法</span></h1>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">作者：凯鲁嘎吉 - 博客园&nbsp;<a href="http://www.cnblogs.com/kailugaji/" target="_blank">http://www.cnblogs.com/kailugaji/</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 本文对<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_COMPLETER_Incomplete_Multi-View_Clustering_via_Contrastive_Prediction_CVPR_2021_paper.pdf" target="_blank">COMPLETER: Incomplete Multi-view Clustering via Contrastive Prediction</a>这篇文章进行讲解，由于论文思路及其数学推导相对简单，因此没把精力放在敲公式与论文复述上，大部分内容来自参考文献。这篇文章阅读前提可以看看<a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/kailugaji/p/12463966.html">变分推断与变分自编码器</a>，所提跨视图对偶预测损失计算时可以参考变分自编码器部分，或者参考<a href="https://spaces.ac.cn/archives/5343">变分自编码器（二）：从贝叶斯观点出发</a>。所提跨视图对比学习损失需要知道概率论中的联合分布、边际分布与条件概率的定义与性质，互信息、信息熵与条件熵等相关知识，可参考[4][5]。更多多视图聚类，请看：随笔分类 - <a href="https://www.cnblogs.com/kailugaji/category/1590733.html" target="_blank">聚类算法简介</a>。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 一般地，多视图<span lang="EN-US">/多模态表示学习（<span lang="EN-US">Multi-view Representation Learning, MvRL）旨在从多视图<span lang="EN-US">/模态数据中学习有效的表示，以改进聚类、分类、检索等下游任务的性能。现有多视图表示学习方法的成功都显式或隐式地要求数据满足视图&ldquo;完备性&rdquo;和&ldquo;一致性&rdquo;假设。其中&ldquo;完备性&rdquo;假设要求每一实例在所有的视图中均需存在，即要求数据是&ldquo;完整的&rdquo;；&ldquo;一致性&rdquo;假设则要求每一实例在所有的视图中均存在正确的对应关系，即要求数据是跨视图&ldquo;对齐的&rdquo;。当数据不满足任一假设时，大多数多视图学习方法，特别在无监督条件下，都难以学习到有效的表示。实际应用中，由于数据采集和传输过程的复杂性，数据可能会丢失部分视图，这就导致了信息不完备下的视图缺失问题。这篇论文针对具有缺失数据的多视图聚类问题进行研究。</span></span></span></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><span lang="EN-US"><span lang="EN-US"><span lang="EN-US">基础补充：互信息I(X; Y)、信息熵H(X), H(Y)、联合熵H(X, Y)与条件熵H(X|Y), H(Y|X)之间的关系[4]。</span></span></span></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><span lang="EN-US"><span lang="EN-US"><span lang="EN-US"><img src="https://img2020.cnblogs.com/blog/1027447/202110/1027447-20211020144708509-1735185749.jpg" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></span></span></span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;" lang="EN-US"><span lang="EN-US"><span lang="EN-US">1. 多视图学习背景</span></span></span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif;" lang="EN-US"><span lang="EN-US"><span lang="EN-US"><img src="https://img2020.cnblogs.com/blog/1027447/202110/1027447-20211019163210671-1896384652.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></span></span></p>
<h2 id="1634632137791"><span style="font-family: 'comic sans ms', sans-serif;">2. 论文创新点</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202110/1027447-20211019163225954-225639194.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<h2 id="1634632153061"><span style="font-family: 'comic sans ms', sans-serif;">3. 方法(以两个视图为例)</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202110/1027447-20211019163304363-1100171297.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202110/1027447-20211019163313017-1394593457.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202110/1027447-20211019163320302-2133168523.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202110/1027447-20211019203240730-976528957.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<h2 id="1634632214687"><span style="font-family: 'comic sans ms', sans-serif;">4. 思考</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">1) 本文所提的方法仅适用于两两视图之间学习，如果你的数据集的视图数为N，N&gt;2，那就得进行N(N-1)/2次两两学习。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">2) Z的大小是[样本个数*隐层维度]，文中视为离散变量，但Q为什么使用的是高斯分布而不是伯努利分布？是否与Z离散矛盾？文中并未给出明确的解释。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">此问题更新：</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202110/1027447-20211025155539653-1041613257.jpg" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p id="1635148346314"><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp;(作者回复说假设Z是连续的，是我理解错了)</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">3) 最后聚类时是将所有视图得到的隐层表示连接在一起形成一个[样本个数*(隐层维度*视图数)]的矩阵进行聚类，用的第二种多视图学习方式，并没有对结果进行融合形成一个[样本个数*隐层维度]的统一特征表示，再进行聚类。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">4) 虽然是老生常谈的问题，但还是想问一下，为什么最后对偶预测损失L只采样一次就能得到好结果？文中也并未提采样这个说法，而是直接给出结果。为什么协方差矩阵设置为对角阵(仅仅是方便计算)？</span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;" lang="EN-US"><span lang="EN-US"><span lang="EN-US">5. 参考文献</span></span></span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[1] Yijie Lin, Yuanbiao Gou, Zitao Liu, Boyun Li, Jiancheng Lv, Xi Peng*, <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_COMPLETER_Incomplete_Multi-View_Clustering_via_Contrastive_Prediction_CVPR_2021_paper.pdf" target="_blank">COMPLETER: Incomplete Multi-view Clustering via Contrastive Prediction</a>, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Jun. 19-25, 2021.</span><br /><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">Paper: <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Lin_COMPLETER_Incomplete_Multi-View_Clustering_via_Contrastive_Prediction_CVPR_2021_paper.html" target="_blank">https://openaccess.thecvf.com/content/CVPR2021/html/Lin_COMPLETER_Incomplete_Multi-View_Clustering_via_Contrastive_Prediction_CVPR_2021_paper.html</a></span><br /><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">Code: <a href="https://github.com/XLearning-SCU/2021-CVPR-Completer" target="_blank">https://github.com/XLearning-SCU/2021-CVPR-Completer</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[2] CCF A类会议CVPR 2021论文收录结果出炉：我院在信息不完备下的多视图学习取得新的进展 <a href="https://sw.scu.edu.cn/info/1182/12482.htm" target="_blank">https://sw.scu.edu.cn/info/1182/12482.htm</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[3]&nbsp;</span><span class="tit tr-fix"><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">【VALSE论文速览-17期】基于对比预测的缺失视图聚类方法</span>&nbsp;</span><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><a href="https://www.bilibili.com/video/BV1Ub4y1a7Zy" target="_blank">https://www.bilibili.com/video/BV1Ub4y1a7Zy</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[4]&nbsp;Chapter 2: Entropy and Mutual Information&nbsp;<a href="https://www.cs.uic.edu/pub/ECE534/WebHome/ch2.pdf" target="_blank">https://www.cs.uic.edu/pub/ECE534/WebHome/ch2.pdf</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[5]&nbsp;X. Ji, A. Vedaldi and J. Henriques, "<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Ji_Invariant_Information_Clustering_for_Unsupervised_Image_Classification_and_Segmentation_ICCV_2019_paper.pdf" target="_blank">Invariant Information Clustering for Unsupervised Image Classification and Segmentation</a>," 2019 IEEE/CVF International Conference on Computer Vision (ICCV), 2019, pp. 9864-9873, doi: 10.1109/ICCV.2019.00996.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[6] 类似论文：Yao-Hung Hubert Tsai, Yue Wu, Ruslan Salakhutdinov and Louis-Philippe Morency, <a href="https://openreview.net/forum?id=-bdp_8Itjwp" target="_blank">Self-supervised Learning from a Multi-view Perspective</a>, International Conference on Learning Representations, 2021.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202110/1027447-20211019172937800-1381666292.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
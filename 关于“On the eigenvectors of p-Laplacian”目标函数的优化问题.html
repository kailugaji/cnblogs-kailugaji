<h1 style="text-align: center;"><span style="font-family: 'comic sans ms', sans-serif;">关于&ldquo;On the eigenvectors of $p$-Laplacian&rdquo;目标函数的优化问题</span></h1>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">作者：凯鲁嘎吉 - 博客园&nbsp;<a href="http://www.cnblogs.com/kailugaji/" target="_blank">http://www.cnblogs.com/kailugaji/</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; </span><span style="font-size: 16px;"><span style="font-family: 'comic sans ms', sans-serif;"><span style="font-family: 'comic sans ms', sans-serif;">图p-拉普拉斯 (Graph p-Laplacian) / p-谱聚类算法 (</span></span><span style="font-family: 'comic sans ms', sans-serif;">p-spectral clustering) 从提出到现在有一些年景了，但关于目标函数的优化问题却很少被提及，而是直接引用前人[2]的结论。这篇博客，我们追根溯源，从最初提出图p-拉普拉斯开始，来探讨目标函数的优化(最小化)问题。</span></span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">1. Graph $p$-Laplacian</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 给定一个带权无向图$G=(V, E)$，其中$V$是边集，$E$是点集。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; $H(V)$: The Hilbert space of real-valued functions on each vertex.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; $H(E)$: The Hilbert space of real-valued functions on each edge.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; The graph $p$-Laplacian ${{\Delta }_{p}}:H(V)\to H(V)$ 为：</span></p>
<p align="center"><span style="font-family: 'comic sans ms', sans-serif; font-size: 18px;">${{\Delta }_{p}}f=-\frac{1}{2}div({{\left\| \nabla f \right\|}^{p-2}}\nabla f)$</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 其中$\Delta $是拉普拉斯算子，$\nabla $是梯度，$div$为散度。当$p=2$时，${{\Delta }_{p}}f={{\Delta }_{2}}f=-\frac{1}{2}div(\nabla f)$，此时，图$p$-拉普拉斯退化为标准的图拉普拉斯。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 通过引入函数$f$的二次型，标准图拉普拉斯算子${{\Delta }_{2}}$满足：</span></p>
<p align="center"><span style="font-family: 'comic sans ms', sans-serif; font-size: 18px;">$\left\langle f,{{\Delta }_{2}}f \right\rangle =\frac{1}{2}\sum\limits_{i,j\in V}{{{w}_{ij}}{{({{f}_{i}}-{{f}_{j}})}^{2}}}$</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 与图拉普拉斯类似，$p$-拉普拉斯算子[1]满足：</span></p>
<p align="center"><span style="font-family: 'comic sans ms', sans-serif; font-size: 18px;">$\left\langle f,{{\Delta }_{p}}f \right\rangle =\frac{1}{2}\sum\limits_{i,j\in V}{{{w}_{ij}}{{\left| {{f}_{i}}-{{f}_{j}} \right|}^{p}}}$</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 对于每一个节点$i\in V$，未规范化的图$p$-拉普拉斯算子为：</span></p>
<p align="center"><span style="font-family: 'comic sans ms', sans-serif; font-size: 18px;">${{(\Delta _{p}^{w})}_{i}}=\sum\limits_{j\in V}{{{w}_{ij}}{{\phi }_{p}}({{f}_{i}}-{{f}_{j}})},i\in V$</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 其中${{\phi }_{p}}(x)={{\left| x \right|}^{p-1}}sig(x)$。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 定义一个特征向量</span></p>
<p align="center"><span style="font-family: 'comic sans ms', sans-serif; font-size: 18px;">${{(\Delta _{p}^{w}f)}_{i}}={{\lambda }_{p}}{{\phi }_{p}}({{f}_{i}}),i\in V$</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 注：特征向量在缩放时是不变的。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 定理1：$f$是$p$-拉普拉斯的特征向量，当且仅当下列函数${{F}_{p}}$在$f$处有临界点：</span></p>
<p align="center"><span style="font-family: 'comic sans ms', sans-serif; font-size: 18px;">${{F}_{p}}(f)=\frac{\left\langle f,{{\Delta }_{p}}f \right\rangle }{\left\| f \right\|_{p}^{p}}=\frac{\sum\nolimits_{ij}{{{w}_{ij}}{{\left| {{f}_{i}}-{{f}_{j}} \right|}^{p}}}}{2\left\| f \right\|_{p}^{p}}$(广义Rayleigh-Ritz原理)</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 其中$\left\| f \right\|_{p}^{p}=\sum\nolimits_{i}{{{\left| {{f}_{i}} \right|}^{p}}},\text{ }i,j\in V$，相应地特征值${{\lambda }_{p}}$通过等式${{\lambda }_{p}}={{F}_{p}}(f)$得出。</span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">2. 用图$p$-拉普拉斯进行$K$聚类</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; Luo等人[2]通过求解下面的$p$-拉普拉斯嵌入问题，引入了对$p$-拉普拉斯全特征向量的一种近似，目标函数为：</span></p>
<p style="text-align: center;"><span style="font-family: 'comic sans ms', sans-serif; font-size: 18px;">$\underset{F}{\mathop{\min }}\,{{J}_{E}}(F)=\sum\limits_{k}{\frac{\sum\nolimits_{ij}{{{w}_{ij}}{{\left| f_{i}^{k}-f_{j}^{k} \right|}^{p}}}}{\left\| {{f}^{k}} \right\|_{p}^{p}}}$</span></p>
<p style="text-align: center;"><span style="font-family: 'comic sans ms', sans-serif; font-size: 18px;">$s.t.\text{ }{{F}^{T}}F=I.$</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 但是，在求导过程中出现错误，原文截图为：</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202011/1027447-20201106155256129-678537716.png" alt="" width="950" height="711" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 也就是从这里起，后面的结果已经无效。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 我推导的为：</span></p>
<p style="text-align: center;"><span style="font-family: 'comic sans ms', sans-serif; font-size: 18px;">$\frac{\partial {{J}_{E}}}{\partial f_{i}^{k}}=\frac{1}{\left\| {{f}^{k}} \right\|_{p}^{p}}\left[ p\sum\nolimits_{j}{{{w}_{ij}}{{\phi }_{p}}(f_{i}^{k}-f_{j}^{k})}-p\sum\nolimits_{j}{{{w}_{ji}}{{\phi }_{p}}(f_{j}^{k}-f_{i}^{k})} \right]-\sum\nolimits_{ij}{{{w}_{ij}}{{\left| f_{i}^{k}-f_{j}^{k} \right|}^{p}}}\cdot \frac{p\cdot {{\phi }_{p}}(f_{i}^{k})}{{{\left( \sum\nolimits_{i}{{{\left| {{f}_{i}} \right|}^{p}}} \right)}^{2}}}$</span></p>
<p style="text-align: center;"><span style="font-family: 'comic sans ms', sans-serif; font-size: 18px;">$=\frac{p}{\left\| {{f}^{k}} \right\|_{p}^{p}}\left[ 2\sum\nolimits_{j}{{{w}_{ij}}{{\phi }_{p}}(f_{i}^{k}-f_{j}^{k})}-\frac{{{\phi }_{p}}(f_{i}^{k})}{\left\| {{f}^{k}} \right\|_{p}^{p}}\sum\nolimits_{ij}{{{w}_{ij}}{{\left| f_{i}^{k}-f_{j}^{k} \right|}^{p}}} \right]$</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 不管怎样，在求导的过程中，总会有系数$p$，而[2]中没有。可以认为这篇文章在求偏导的过程中出现问题。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 算法总体流程：</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202011/1027447-20201106155339456-2045178729.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 注：(22)公式出错。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 有趣的是，直接引用这篇文章结论的大有论文在。例如，这一篇[4]</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202011/1027447-20201106155450625-908644165.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202011/1027447-20201106155507129-1597810516.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 更有趣的是，时隔整整十年，[3]明确指出[2]中的推导错误：</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202011/1027447-20201106155616871-245244192.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; [3]给出了他自己提的目标函数与求导公式：</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202011/1027447-20201106155651837-155898724.png" alt="" width="789" height="95" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202011/1027447-20201106155712748-1999684452.png" alt="" width="1151" height="244" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 可以看出，[3]的推导结论与我的推导是一致的，只是目标函数分母部分有无系数2。</span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">3. 参考文献</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; [1] B&uuml;hler, Thomas &amp; Hein, Matthias. (2009). <a href="https://www.ml.uni-saarland.de/Publications/BueHei-pSpectralClustering2009.pdf" target="_blank">Spectral clustering based on the graph Laplacian</a>. Proceedings of the 26th International Conference On Machine Learning, ICML 2009. 382. 11-88. 10.1145/1553374.1553385.&nbsp;&nbsp;</span><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">Code: <a href="https://www.ml.uni-saarland.de/code/pSpectralClustering/pSpectralClustering.htm" target="_blank">p-Spectral Clustering</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; [2] Luo, Dijun &amp; Huang, Heng &amp; Ding, Chris &amp; Nie, Feiping. (2010). <a href="https://link.springer.com/content/pdf/10.1007%2Fs10994-010-5201-z.pdf" target="_blank">On the eigenvectors of p-Laplacian</a>. Machine Learning. 81. 37-51. 10.1007/s10994-010-5201-z.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; [3] Pasadakis, Dimosthenis &amp; Alappat, Christie &amp; Schenk, Olaf &amp; Wellein, Gerhard. (2020). <a href="https://arxiv.org/pdf/2008.13210.pdf" target="_blank">$K$-way $p$-spectral clustering on Grassmann manifolds</a>.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; [4]&nbsp;W. Liu, X. Ma, Y. Zhou, D. Tao and J. Cheng, "<a href="https://viplab.cis.um.edu.mo/publications/journal/p-Laplacian%20Regularization%20for%20Scene%20Recognition.pdf" target="_blank">$p$-Laplacian Regularization for Scene Recognition</a>," in IEEE Transactions on Cybernetics, vol. 49, no. 8, pp. 2927-2940, Aug. 2019, doi: 10.1109/TCYB.2018.2833843.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; [5]&nbsp;<a href="https://zhuanlan.zhihu.com/p/85287578" target="_blank">拉普拉斯矩阵与拉普拉斯算子的关系</a> - 知乎&nbsp;</span></p>
<p><strong><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><span style="color: #ff0000;">最后的思考：</span>做研究切忌浮躁，要追根溯源，明白公式的来龙去脉，自己动手，丰衣足食。</span></strong></p>
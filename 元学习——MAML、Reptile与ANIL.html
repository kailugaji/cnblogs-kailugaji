<h1 style="text-align: center;"><span style="font-family: 'comic sans ms', sans-serif;">元学习&mdash;&mdash;MAML、Reptile与ANIL</span></h1>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">作者：凯鲁嘎吉 - 博客园&nbsp;<a href="http://www.cnblogs.com/kailugaji/" target="_blank">http://www.cnblogs.com/kailugaji/</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; &nbsp; &nbsp; 之前介绍过<a href="https://www.cnblogs.com/kailugaji/p/14985045.html" target="_blank">元学习&mdash;&mdash;从MAML到MAML++</a>，这次在此基础上进一步探讨，深入了解<a href="http://proceedings.mlr.press/v70/finn17a/finn17a.pdf" target="_blank">MAML</a>的本质，引出MAML高效学习的原因究竟是快速学习，学到一个很厉害的初始化参数，还是特征重用，初始化参数与最终结果很接近？因此得到<a href="https://arxiv.org/pdf/1909.09157v2.pdf" target="_blank">ANIL(Almost No Inner Loop)</a>，随后我们阅读了Reptile&mdash;&mdash;<a href="https://arxiv.org/pdf/1803.02999v3.pdf" target="_blank">On first-order meta-learning algorithms</a>，另一种元学习方法，并比较了MAML、Reptile与模型预训练之间的区别。</span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">1.&nbsp;Meta Learning vs Machine Learning</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202108/1027447-20210818145903016-1351581098.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">2.&nbsp;MAML vs Model Pre-Training</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202108/1027447-20210818145912063-1970208586.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">3.&nbsp;MAML&mdash;&mdash;Feature Reuse</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202108/1027447-20210818145920085-1774736328.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">4.&nbsp;MAML vs ANIL</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202108/1027447-20210818145929135-173471179.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;">MAML的目标是学习一个参数𝜃使得其经过一个梯度迭代就可以在新任务上达到最好的性能。</span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;">内循环：与具体任务相关的任务适配参数的更新(自适应具体任务)</span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;">外循环：整体任务空间上的模型参数的更新(元初始化)</span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">5.&nbsp;Reptile: On First-Order Meta-Learning Algorithms</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202108/1027447-20210818145936675-346118291.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">6.&nbsp;MAML, Model Pre-Training, and Reptile</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202108/1027447-20210818145944324-1939744861.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">7. 参考文献</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[1] GitHub - Fafa-DL/Lhy_Machine_Learning: 李宏毅2021春季机器学习课程课件及作业 <a href="https://github.com/Fafa-DL/Lhy_Machine_Learning" target="_blank">https://github.com/Fafa-DL/Lhy_Machine_Learning</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[2] Finn, C., Abbeel, P. &amp; Levine, S. <a href="http://proceedings.mlr.press/v70/finn17a/finn17a.pdf" target="_blank">Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</a>. ICML 2017.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[3] Aniruddh Raghu, Maithra Raghu, Samy Bengio, Oriol Vinyals, <a href="https://arxiv.org/pdf/1909.09157v2.pdf" target="_blank">Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML</a>, ICLR, 2020.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[4] Nichol A, Achiam J, Schulman J. <a href="http://export.arxiv.org/pdf/1803.02999v3" target="_blank">On first-order meta-learning algorithms.</a> arXiv preprint arXiv:1803.02999, 2018.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[5] Nichol A, Schulman J. <a href="https://arxiv.org/pdf/1803.02999v1.pdf" target="_blank">Reptile: a scalable metalearning algorithm</a>. arXiv preprint arXiv:1803.02999, 2018, 2(3): 4.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[6] Reptile: A Scalable Meta-Learning Algorithm. OpenAI. <a href="https://openai.com/blog/reptile/" target="_blank">https://openai.com/blog/reptile/</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[7] 一文入门元学习（Meta-Learning）（附代码） - 知乎 <a href="https://zhuanlan.zhihu.com/p/136975128" target="_blank">https://zhuanlan.zhihu.com/p/136975128</a></span></p>
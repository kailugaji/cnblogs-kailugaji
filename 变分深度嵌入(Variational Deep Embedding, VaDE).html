<h1 style="text-align: center;"><span style="font-family: 'comic sans ms', sans-serif;">变分深度嵌入(Variational Deep Embedding, VaDE)</span></h1>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">作者：凯鲁嘎吉 - 博客园&nbsp;<a href="http://www.cnblogs.com/kailugaji/" target="_blank">http://www.cnblogs.com/kailugaji/</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; </span><span style="font-size: 16px;"><span style="font-family: 'comic sans ms', sans-serif;"><span style="font-family: 'comic sans ms', sans-serif;">这篇博文主要是对论文&ldquo;</span></span><span style="font-family: 'comic sans ms', sans-serif;">Variational Deep Embedding: An Unsupervised and Generative Approach to Clustering&rdquo;的整理总结，阅读这篇博文的前提条件是：了解<a href="https://www.cnblogs.com/kailugaji/p/9648508.html" target="_blank">高斯混合模型用于聚类的算法</a>，了解<a href="https://www.cnblogs.com/kailugaji/p/12463966.html" target="_blank">变分推断与变分自编码器</a>。在知道高斯混合模型(GMM)与变分自编码器(VAE)之后，VaDE实际上是将这两者结合起来的一个产物。与VAE相比，VaDE在公式推导中多了一个变量c。与GMM相比，变量c就相当于是GMM中的隐变量z，而隐层得到的特征z相当于原来GMM中的数据x。下面主要介绍VaDE模型的变分下界(损失函数)L(x)的数学推导过程。推导过程用到了概率论与数理统计的相关知识。</span></span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">1. 前提公式</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202005/1027447-20200513152436164-650417344.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-size: 16px;">计算过程中用到了正态分布的一阶矩与二阶矩计算公式。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202007/1027447-20200708160517228-303337723.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202005/1027447-20200514102000731-296004083.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">2. VaDE损失函数公式推导过程</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202005/1027447-20200513152618726-1233522561.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202005/1027447-20200513152728364-496426645.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">最终的聚类结果是由q(c|x)得到的，q(c|x)相当于GMM中的隐变量的后验概率&gamma;。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202005/1027447-20200513152652240-1428587246.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p>&nbsp;<span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;">下面将损失函数拆成5项，并一项一项进行求解。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202005/1027447-20200513152747224-612785647.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202005/1027447-20200513152803709-1328138832.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202005/1027447-20200513152819408-1248983720.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202005/1027447-20200513152842809-1980566544.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202005/1027447-20200513152900168-2142233358.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202005/1027447-20200513152914960-465070745.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">3. VaDE算法总体流程</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif;"><img src="https://img2020.cnblogs.com/blog/1027447/202005/1027447-20200513152951139-324219815.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">4. 疑问</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 1）GMM算法的参数pi并没有进行归一化处理，在更新过程中能保证pi的和始终为1吗？这个问题在<a href="https://github.com/slim1017/VaDE/issues/4" target="_blank">作者评论里面</a>有回答，说pi相比于参数miu, sigma来说，对结果影响不大，但又有人问了，如果遇到非平衡数据呢？这种情况下pi的影响还是比较大的。在代码里也不难实现，加一行代码，类似于pi/sum(pi)就行。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202006/1027447-20200629211955267-1139200590.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 2）后验概率&gamma;在代码里并不参与更新，为什么不和GMM的其他参数(pi, miu, sigma)一样进行梯度下降更新呢？而是直接套公式？有什么数学依据吗？这个在<a href="https://github.com/slim1017/VaDE/issues/17" target="_blank">作者评论里面</a>有人提到过，但是未被回复。其实直接ELBO目标对&gamma;求偏导令其为0，用这种求极值的方式求解&gamma;也没有问题，最后记得对&gamma;进行归一化。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202006/1027447-20200629212035624-289152816.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p>&nbsp; &nbsp; <span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">3）预训练到底是怎么做到的，仅仅是用SAE训练得到的结果吗？原作者代码里面只给出了预训练之后得到的具体参数，并没有给出预训练的代码。预训练这个问题在<a href="https://github.com/slim1017/VaDE/issues/5" target="_blank">作者评论里面</a>有被提到。预训练阶段还是非常关键的一步，当然，有人是这样做的：预训练使用VAE模型。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;"><img src="https://img2020.cnblogs.com/blog/1027447/202007/1027447-20200708161531116-1693919953.png" alt="" loading="lazy" style="display: block; margin-left: auto; margin-right: auto;" /></span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;">&nbsp; &nbsp;4) 代码中生成z的方式与VAE一模一样，而原文中的图示以及3.1节部分中的描述是z从${\mu }_c$与${\sigma }_c$而来，而公式(14)又与VAE一致了，原文中的表述并不统一，且代码与原文部分表述不符。</span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;">&nbsp; &nbsp; &nbsp; &nbsp; 论文中说的是$\pi $、${\mu }_c$与${\sigma }_c$用GMM来初始化，代码里分别初始化为取平均、零矩阵、单位矩阵。不过问题也不大，自己改一下代码就OK。</span></p>
<p><span style="font-size: 16px; font-family: 'comic sans ms', sans-serif;">如果能解决我的疑问，欢迎在评论区回复，一起探讨~</span></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">5. 参考文献</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[1]&nbsp;<a href="https://www.cnblogs.com/kailugaji/p/9648508.html" target="_blank">聚类&mdash;&mdash;GMM - 凯鲁嘎吉 - 博客园</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[2]&nbsp;<a href="https://www.cnblogs.com/kailugaji/p/12463966.html" target="_blank">变分推断与变分自编码器 - 凯鲁嘎吉 - 博客园</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[3]&nbsp;Jiang Z , Zheng Y , Tan H , et al. <a href="https://arxiv.org/pdf/1611.05148.pdf" target="_blank">Variational Deep Embedding: An Unsupervised and Generative Approach to Clustering</a>. 2016.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[4] VaDE代码：</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; &nbsp;GitHub - slim1017/VaDE: <a href="https://github.com/slim1017/VaDE" target="_blank">Python code for paper - Variational Deep Embedding : A Generative Approach to Clustering</a></span></p>
<p>&nbsp; &nbsp; &nbsp;&nbsp;<span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">GitHub - GuHongyang/VaDE-<a href="https://github.com/GuHongyang/VaDE-pytorch" target="_blank">pytorch: the reproduce of Variational Deep Embedding : A Generative Approach to Clustering Requirements by pytorch</a></span></p>
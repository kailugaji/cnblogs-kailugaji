<h1 style="text-align: center;"><span style="font-family: 'comic sans ms', sans-serif;">Extreme Learning Machine<br /></span></h1>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">作者：凯鲁嘎吉 - 博客园&nbsp;<a href="http://www.cnblogs.com/kailugaji/" target="_blank">http://www.cnblogs.com/kailugaji/</a></span></p>
<p><strong><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px; color: #ff0000;">更新：只做科普，别做学术。</span></strong></p>
<h2>1. ELM</h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 2004年南洋理工大学黄广斌提出了ELM算法。极限学习机（ELM Extreme Learning Machine)是一种快速的的单隐层前馈神经网络（SLFN）训练算法。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 该算法的特点是在网络参数的确定过程中,隐层节点参数(a,b)随机选取,在训练过程中无需调节，只需要设置隐含层神经元的个数，便可以获得唯一的最优解;而网络的外权（即输出权值）是通过最小化平方损失函数得到的最小二乘解（最终化归成求解一个矩阵的 Moore-Penrose 广义逆问题）.这样网络参数的确定过程中无需任何迭代步骤,从而大大降低了网络参数的调节时间。与传统的训练方法相比，该方法具有学习速度快、泛化性能好等优点。</span></p>
<p><img src="https://img2018.cnblogs.com/blog/1027447/202001/1027447-20200103203628590-1132011161.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></p>
<p><img src="https://img2018.cnblogs.com/blog/1027447/202001/1027447-20200103202101855-763233011.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></p>
<h2>2. H-ELM</h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; Hierarchical Extreme Learning Machine (H-ELM)是2015年提出的一个ELM的改进算法。分为两个阶段：</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 1. 非监督式的特征编码。在第一阶段，基于ELM的稀疏自编码器被设计用来从输入数据中抽取多层的稀疏特征。通过逐层自编码获得每层的权重矩阵，权重确定后，无需微调。</span><br /><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 2. 监督式的特征分类。在第二阶段，第一阶段获得的高层次特征（维度可能比原始数据大）将被一个随机矩阵打散，将打散后的数据作为原始ELM的输入，最后用原始ELM来解决分类或者回归问题。</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; 与ELM的区别在于自编码阶段，权重矩阵的惩罚项用的是L1范数，参数的更新公式用</span><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">Fast Iterative Shrinkage-thresholding (FISTA)求解，</span><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">而ELM的权重惩罚项用的L2范数，用岭回归求解。</span></p>
<p><img src="https://img2018.cnblogs.com/common/1027447/202001/1027447-20200112191152318-1631950260.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></p>
<p><img src="https://img2018.cnblogs.com/common/1027447/202001/1027447-20200112191203512-293002821.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></p>
<p><img src="https://img2018.cnblogs.com/common/1027447/202001/1027447-20200112195908413-587696097.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></p>
<h2>3. RVFL</h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">&nbsp; &nbsp; Random Vector Functional-link Network (RVFL)算法是1994年提出的算法，与ELM相比，它增加了从输入层到输出层的连接权重。输入层到隐层的权重与隐层的偏置还是随机赋权，只有输入层到输出层与隐层到输出层的权重需要用最小二乘法或者其他方法求解。</span></p>
<p><img src="https://img2018.cnblogs.com/common/1027447/202001/1027447-20200112191414146-251142331.png" alt="" style="display: block; margin-left: auto; margin-right: auto;" /></p>
<h2><span style="font-family: 'comic sans ms', sans-serif;">4. 参考</span></h2>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[1] ELM官方网址：<a href="https://www.ntu.edu.sg/home/egbhuang/" target="_blank">Extreme Learning Machines</a><br /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[2] Huang G B, Zhu Q Y, Siew C K. <a href="http://www.di.unito.it/~cancelli/retineu11_12/ELM-NC-2006.pdf" target="_blank">Extreme learning machine: theory and applications</a>[J]. Neurocomputing, 2006, 70(1-3): 489-501.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[3]&nbsp;<a id="cb_post_title_url" class="postTitle2" href="https://www.cnblogs.com/kailugaji/p/9002054.html">MATLAB程序：ELM极速学习机</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[4]&nbsp;<a href="https://blog.csdn.net/kay_lugaji/article/details/83241736" target="_blank">论战Yann LeCun：谁能解释极限学习机（ELM）牛X在哪里？</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[5]&nbsp;</span><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">Tang J, Deng C, Huang G B. <a href="https://sci-hub.tw/10.1109/TNNLS.2015.2424995" target="_blank">Extreme learning machine for multilayer perceptron</a>[J]. IEEE transactions on neural networks and learning systems, 2015, 27(4): 809-821.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[6]&nbsp;Pao Y H, Park G H, Sobajic D J.&nbsp;<a href="https://sci-hub.tw/https://doi.org/10.1016/0925-2312(94)90053-1" target="_blank">Learning and generalization characteristics of the random vector functional-link net</a>[J]. Neurocomputing, 1994, 6(2): 163-180.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[7] <a href="https://blog.csdn.net/lbc3402785/article/details/88350438" target="_blank">伪逆总结 - CSDN</a><br /></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[8] 对ELM的质疑：<a href="https://elmorigin.wixsite.com/originofelm" target="_blank">Extreme Learning Machine: Duplicates Others' Papers from 1988-2007</a></span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[9]&nbsp;王常飞. <a href="http://caj.d.cnki.net/kfdoc/down.aspx?uid=WEEvREcwSlJHSldRa1Fhb09pSnNveU82WVJydndzZ2RabFJTV0h4cjZibz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!&amp;fn=ZuO0yQXZaZGZe15cyPqXvsGs7zuid39O&amp;title=%e8%9e%8d%e5%90%88%e5%88%86%e5%b1%82%e6%9e%81%e9%99%90%e5%ad%a6%e4%b9%a0%e6%9c%ba%e7%ae%97%e6%b3%95%e7%a0%94%e7%a9%b6_%e7%8e%8b%e5%b8%b8%e9%a3%9e&amp;dbcode=cmfd&amp;db=CMFD201901&amp;dflag=cajdown&amp;lang=gb&amp;t=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhcHBpZCI6IjgwNzA5IiwidGltZXN0YW1wIjoxNTc4ODMwNDc2LCJub25jZSI6IlB4TGI3V0Rrd1oifQ.Br9bnZPTi7ljyfRMI5cwgiqdjUv67s3rdaesjO9k7v8&amp;zt=I140&amp;doi=CNKI:CDMD:2.1018.263838&amp;sid=%e4%b8%ad%e5%bf%83%e7%bd%91%e7%ab%99&amp;filetitle=%c8%da%ba%cf%b7%d6%b2%e3%bc%ab%cf%de%d1%a7%cf%b0%bb%fa%cb%e3%b7%a8%d1%d0%be%bf_%cd%f5%b3%a3%b7%c9" target="_blank">融合分层极限学习机算法研究</a>[D]. 湘潭大学, 2018.</span></p>
<p><span style="font-family: 'comic sans ms', sans-serif; font-size: 16px;">[10]&nbsp;<a id="cb_post_title_url" class="postTitle2" href="https://www.cnblogs.com/louisanu/p/12045861.html">软阈值迭代算法（ISTA）和快速软阈值迭代算法（FISTA）</a></span></p>